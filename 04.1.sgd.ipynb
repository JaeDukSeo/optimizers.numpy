{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize the Beale Function using Stochastic Gradient Descent\n",
    "\n",
    "### Gradient Descent\n",
    "$$ \\mathbf{w}' = \\mathbf{w} - \\eta \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} $$\n",
    "\n",
    "* Another notation\n",
    "$$ \\mathbf{w}_{t+1} = \\mathbf{w}_{t} - \\eta_{t} \\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}_{t}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LogNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beale function\n",
    "\n",
    "$$ f(x, y) = (1.5 - x + xy)^{2} + (2.25 - x + xy^{2})^{2} + (2.625 - x +xy^{3})^{2}$$\n",
    "\n",
    "* analytic solution (global minima)\n",
    "  * $(x, y) = (3, 0.5)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, y: (1.5 - x + x*y)**2 + (2.25 - x + x*y**2)**2 + (2.625 - x + x*y**3)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minima = np.array([3., .5])\n",
    "minima_ = minima.reshape(-1, 1)\n",
    "print(\"minima (1x2 row vector shape): {}\".format(minima))\n",
    "print(\"minima (2x1 column vector shape):\")\n",
    "print(minima_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting together our points to plot in a 3D plot\n",
    "number_of_points = 50\n",
    "margin = 4.5\n",
    "x_min = 0. - margin\n",
    "x_max = 0. + margin\n",
    "y_min = 0. - margin\n",
    "y_max = 0. + margin\n",
    "x_points = np.linspace(x_min, x_max, number_of_points) \n",
    "y_points = np.linspace(y_min, y_max, number_of_points)\n",
    "x_mesh, y_mesh = np.meshgrid(x_points, y_points)\n",
    "z = np.array([f(xps, yps) for xps, yps in zip(x_mesh, y_mesh)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D plot with minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "#%pylab\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection='3d', elev=80, azim=-100)\n",
    "\n",
    "ax.plot_surface(x_mesh, y_mesh, z, norm=LogNorm(), rstride=1, cstride=1, \n",
    "                edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "ax.plot(*minima_, f(*minima_), 'r*', markersize=20)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "\n",
    "ax.set_xlim((x_min, x_max))\n",
    "ax.set_ylim((y_min, y_max))\n",
    "\n",
    "#plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour plot with minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.contour(x_mesh, y_mesh, z, levels=np.logspace(-.5, 5, 35), norm=LogNorm(), cmap=plt.cm.jet)\n",
    "ax.plot(*minima, 'r*', markersize=20)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "ax.set_xlim((x_min, x_max))\n",
    "ax.set_ylim((y_min, y_max))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientDescentOptimizer():\n",
    "  def __init__(self, function, x_init=None, y_init=None, learning_rate=0.01):\n",
    "    self.f = function\n",
    "    scale = 3.0\n",
    "    if x_init is not None:\n",
    "      self.x = x_init\n",
    "    else:\n",
    "      self.x = np.random.uniform(low=-scale, high=scale)\n",
    "    if y_init is not None:\n",
    "      self.y = y_init\n",
    "    else:\n",
    "      self.y = np.random.uniform(low=-scale, high=scale)\n",
    "    print(\"x_init: {:.3f}\".format(self.x))\n",
    "    print(\"y_init: {:.3f}\".format(self.y))\n",
    "    \n",
    "    self.lr = learning_rate\n",
    "  \n",
    "  def func(self, x, y):\n",
    "    \"\"\"Beale function.\n",
    "    \n",
    "    Args:\n",
    "      x: x-dimension of inputs\n",
    "      y: y-dimension of inputs\n",
    "      \n",
    "    Returns:\n",
    "      z: Beale function value at (x, y)\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    z = \n",
    "    return z\n",
    "  \n",
    "  def gradients(self, x, y):\n",
    "    \"\"\"Gradient of Beale function.\n",
    "    \n",
    "    Args:\n",
    "      x: x-dimension of inputs\n",
    "      y: y-dimension of inputs\n",
    "      \n",
    "    Returns:\n",
    "      dx: gradient of Beale function with respect to x-dimension of inputs\n",
    "      dy: gradient of Beale function with respect to y-dimension of inputs\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    dx = \n",
    "    dy = \n",
    "    return dx, dy\n",
    "  \n",
    "  def weights_update(self):\n",
    "    \"\"\"Weights update using Gradient descent.\n",
    "    \n",
    "      w' = w - lr * dL/dw\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    self.x = \n",
    "    self.y = \n",
    "    \n",
    "  def train(self, max_steps):\n",
    "    self.z_history = []\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    pre_z = 0.0\n",
    "    print(\"steps: {}  z: {:.6f}  x: {:.5f}  y: {:.5f}\".format(0, self.func(self.x, self.y), self.x, self.y))\n",
    "    \n",
    "    file = open('sgd.txt', 'w')\n",
    "    file.write(\"{:.5f}  {:.5f}\\n\".format(self.x, self.y))\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "      self.z = self.func(self.x, self.y)\n",
    "      self.z_history.append(self.z)\n",
    "      self.x_history.append(self.x)\n",
    "      self.y_history.append(self.y)\n",
    "\n",
    "      self.dx, self.dy = self.gradients()\n",
    "      self.weights_update()\n",
    "      file.write(\"{:.5f}  {:.5f}\\n\".format(self.x, self.y))\n",
    "      \n",
    "      if (step+1) % 100 == 0:\n",
    "        print(\"steps: {}  z: {:.6f}  x: {:.5f}  y: {:.5f}  dx: {:.5f}  dy: {:.5f}\".format(step+1, self.func(self.x, self.y), self.x, self.y, self.dx, self.dy))\n",
    "        \n",
    "      if np.abs(pre_z - self.z) < 1e-7:\n",
    "        print(\"Enough convergence\")\n",
    "        print(\"steps: {}  z: {:.6f}  x: {:.5f}  y: {:.4f}\".format(step+1, self.func(self.x, self.y), self.x, self.y))\n",
    "        self.z = self.func(self.x, self.y)\n",
    "        self.z_history.append(self.z)\n",
    "        self.x_history.append(self.x)\n",
    "        self.y_history.append(self.y)\n",
    "        break\n",
    "        \n",
    "      pre_z = self.z\n",
    "    file.close()\n",
    "\n",
    "    self.x_history = np.array(self.x_history)\n",
    "    self.y_history = np.array(self.y_history)\n",
    "    self.path = np.concatenate((np.expand_dims(self.x_history, 1), np.expand_dims(self.y_history, 1)), axis=1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a `GradientDescentOptimizer()` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = GradientDescentOptimizer(f, x_init=0.7, y_init=1.4, learning_rate=0.01)\n",
    "#opt = GradientDescentOptimizer(f, x_init=2., y_init=2., learning_rate=0.001)\n",
    "#opt = GradientDescentOptimizer(f, x_init=-1., y_init=0., learning_rate=0.01)\n",
    "#opt = GradientDescentOptimizer(f, x_init=-2., y_init=0., learning_rate=0.01) # local minimum\n",
    "#opt = GradientDescentOptimizer(f, x_init=-3., y_init=0., learning_rate=0.01) # local minimum\n",
    "#opt = GradientDescentOptimizer(f, x_init=None, y_init=None, learning_rate=0.01) # random initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "opt.train(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Global minima\")\n",
    "print(\"x*: {:.2f}  y*: {:.2f}\".format(minima[0], minima[1]))\n",
    "print(\"Solution using the gradient descent\")\n",
    "print(\"x: {:.4f}  y: {:.4f}\".format(opt.x, opt.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beale function plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Beale function\n",
    "plt.title('Beale Function')\n",
    "plt.xlabel('Number of steps')\n",
    "plt.ylabel('Beale function value')\n",
    "plt.plot(opt.z_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting together our points to plot in a 3D plot\n",
    "number_of_points = 50\n",
    "margin = 4.5\n",
    "x_min = 0. - margin\n",
    "x_max = 0. + margin\n",
    "y_min = 0. - margin\n",
    "y_max = 0. + margin\n",
    "x_points = np.linspace(x_min, x_max, number_of_points) \n",
    "y_points = np.linspace(y_min, y_max, number_of_points)\n",
    "x_mesh, y_mesh = np.meshgrid(x_points, y_points)\n",
    "z = np.array([f(xps, yps) for xps, yps in zip(x_mesh, y_mesh)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D plot with learning path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "#%matplotlib notebook\n",
    "#%pylab\n",
    "\n",
    "path = opt.path\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection='3d', elev=80, azim=-100)\n",
    "\n",
    "ax.plot_surface(x_mesh, y_mesh, z, norm=LogNorm(), rstride=1, cstride=1, \n",
    "                edgecolor='none', alpha=.8, cmap=plt.cm.jet)\n",
    "ax.plot(*minima_, f(*minima_), 'r*', markersize=20)\n",
    "ax.quiver(path[0,:-1], path[1,:-1], opt.func(*path[::,:-1]),\n",
    "          path[0,1:]-path[0,:-1], path[1,1:]-path[1,:-1],\n",
    "          opt.func(*path[::,1:]) - opt.func(*path[::,:-1]),\n",
    "          color='k', length=1, normalize=True)\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "\n",
    "ax.set_xlim((x_min, x_max))\n",
    "ax.set_ylim((y_min, y_max))\n",
    "\n",
    "#plt.draw()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour plot with learning path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "ax.contour(x_mesh, y_mesh, z, levels=np.logspace(-.5, 5, 35), norm=LogNorm(), cmap=plt.cm.jet)\n",
    "ax.plot(*minima, 'r*', markersize=20)\n",
    "ax.quiver(path[0,:-1], path[1,:-1], path[0,1:]-path[0,:-1], path[1,1:]-path[1,:-1],\n",
    "          scale_units='xy', angles='xy', scale=1, color='k')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "ax.set_xlim((x_min, x_max))\n",
    "ax.set_ylim((y_min, y_max))\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
