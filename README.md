# Various Optimizers based on Gradient Descent
* Final update: 2018. 11. 28.
* All right reserved @ Il Gu Yi 2018

## Getting Started

### Prerequisites
* Python 3.6
* `numpy`, `matplotlib`
* Jupyter notebook
* OS X and Linux (Not validated on Windows but probably it might work)


## Contents

### Linear Regression using Gradient Descent
* Gradient Descent
* Stochastic Gradient Descent
* Coordinate Gradient Descent

### Optimization of Beale Function using Various Gradient Descent Algorithms
* Gradient Descent
* Momentum
* Nesterov Momentum
* Adagrad
* RMSprop
* Adam



## Author
Il Gu Yi
